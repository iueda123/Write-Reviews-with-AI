# LLM CLI Tool を使ったシステマティックレビュー用Data Extraction作業：実践ガイド

*本文書は、LLM CLIツールを使用したシステマティックレビューのデータ抽出に関する包括的なガイドとして作成された。技術の進歩に合わせて定期的な更新が推奨される。*

## 1. はじめに

システマティックレビュー（SR）は、特定の研究問題に対する既存の証拠を体系的に収集、評価、統合する重要な研究手法である。しかし、大量の文献からのデータ抽出作業は時間とリソースを大量に消費する。近年、大規模言語モデル（LLM）を活用したCLIツールが登場し、このプロセスを効率化する可能性が注目されている。

本文書は、LLM CLIツールを使用してシステマティックレビューのデータ抽出を行う際の実践ガイドである。技術的な基礎知識から実際の運用まで、包括的に解説する。

## 2. 前提知識

### 2.1 LLM CLIツールとは

LLM CLIツールは「AI CLIツール」「LLM CLIツール」「AIコーディングアシスタントCLI」などと呼ばれ、Large Language Model（LLM）をコマンドラインインターフェース（CLI）で利用できる開発者向けアプリケーションである。

**CLI環境について：**
- **Windows**: CommandPrompt や PowerShell
- **Linux・Mac**: Terminal

### 2.2 主要なLLM CLIツール

LLMエージェントサービスは段階的に発展してきた。GitHub Copilotが2021年6月に技術プレビューとして開始され、2022年6月に一般提供開始となったのが先駆けである。その後、2024年後半からCursor等の新しいツールが登場し、2025年に入ってClaude Code（2月研究プレビュー、5月一般提供）、Gemini CLI（7月発表）といったローカル型CLIツールが相次いで登場している。

**代表的なツール：**
- GitHub Copilot（2021年開始、2022年一般提供）
- Cursor（2024年後半）
- Claude Code（2025年2月プレビュー、5月一般提供）
- Gemini CLI（2025年7月）
- OpenHands（旧OpenDevin、2024年開発開始）

多くのツールがオープンソースで公開されており、現在も新しいものが継続的に登場している。

### 2.3 インストールと配布

LLM CLIツールは主にnpm（Node Package Manager）を介して配布され、npxコマンドでインストールするパターンが一般的である。

**Node.jsが選ばれる理由：**
- 配布の容易さと安定性
- クロスプラットフォーム性
- Web APIとの高い相性
- 即利用性（npx）

Pythonは研究や解析では強力だが、CLIの簡単な配布という点ではNode.jsが圧倒的に有利である。

### 2.4 CLIを選ぶ理由

**CLI使用の利点：**
- エラーの入り込む余地を減らせる
- GUI操作の違いによる結果の差異をなくせる
- 再現性が高い
- 汎用性が高い

### 2.5 参考：プロジェクトレベルの指示ファイル

LLM CLIツールでは、作業ディレクトリに置く指示ファイルで、プロジェクト固有の方針やルールを自動的に参照できる。

**主要ツールと指示ファイル：**
- Claude Code → `Claude.md`
- Gemini CLI → `Gemini.md`等
- Codex CLI → `Codex.md`等

**記述内容：**
- コーディング規約
- 技術スタック（テストフレームワーク等）
- 出力フォーマット
- 作業スタイル

**メリット：**
- 一貫した出力
- 効率化（毎回のルール入力不要）
- チーム開発での統一性



## 3. プロンプトエンジニアリングの基礎

### 3.1 参考資料

- 「LLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発」（2025/5/16）
  - John Berryman, Albert Ziegler 著, 服部佑樹 翻訳

### 3.2 プロンプト作成の基本コツ

**効果的なプロンプトの原則：**
- 否定的表現を避ける
- ルールに理由を付ける
- 過度に厳格な表現は避ける

「LLMのプロンプトエンジニアリング」（89p参照）

### 3.2 プロンプト手法

**Zero-shot プロンプティング：**
例を与えずに直接タスクを指示する手法

**Few-shot プロンプティング：**
- 具体例を提示することで効果的な結果を得る
- **問題点：**
  - コンテキストが増えるほどスケーラビリティが低下
  - 結果が例に引きずられるバイアス
  - 意図しない不適切なパターンを生み出すリスク

**Chain-of-Thought (CoT)：**
段階的思考プロセスを明示する手法

### 3.3 プロンプトへのMarkdown の活用

Markdownは文章をシンプルな記号で装飾できる軽量マークアップ言語である。

**Markdownの特徴：**
- プレーンテキストで記述可能
- 読みやすく書きやすい
- HTMLなどに変換可能

「LLMのプロンプトエンジニアリング」（p126）において、LLMで分析レポートを生成させる際にはMarkdownでプロンプトを書くことが推奨されている。


### 3.4 適切なプロンプト構造

**導入部：**
- コンテキスト（文脈）を設定
- 早い段階で依頼の焦点を定める
- 取り扱える情報には限りがあるため、焦点の明確化が重要

**中間部（Lost in the Middle問題）：**
- プロンプトの末尾に近い情報ほど、モデルに大きな影響を与えやすい
- モデルは冒頭と末尾の情報は思い出しやすいが、中間部の情報は活用が困難になる傾向

**リフォーカス・移行部：**
- 問題の焦点を明確化
- 問題の説明から解決へと移行

「LLMのプロンプトエンジニアリング」（120p参照）

## 4. システマティックレビューへのLLM活用に関する最新研究

### 4.1 研究の概要

大規模言語モデル（LLMs）がシステマティックレビュー（SR）のプロセスを効率化する可能性を示す複数の研究が発表されている。これらの研究は、LLMsが人間の作業負担を軽減し、効率を高めつつ、信頼性の高い結果を維持できることを実証している。

### 4.2 主要研究の詳細

#### 4.2.1 Cao et al. (2025) - スクリーニングプロセスの効率化

**出典：** Ann Intern Med. 2025 Mar;178(3):389-401
**URL：** https://pubmed.ncbi.nlm.nih.gov/39993313/

**研究内容：**
システマティックレビューの記事スクリーニングプロセス効率化のため、LLM用の汎用プロンプトテンプレートを開発・評価した。

**主な発見：**
- 最適化されたプロンプトが従来のゼロショットプロンプトと比較して、抄録と全文スクリーニングの両方で高い感度と特異度を達成
- GPT4-0125-previewモデル使用時、人間のスクリーニングに比べて時間とコストを大幅に削減
- システマティックレビューの作業負担軽減に大きく貢献

#### 4.2.2 Lai et al. (2024) - バイアスリスク評価への応用

**出典：** JAMA Netw Open. 2024 May 22;7(5):e2412687
**URL：** https://pmc.ncbi.nlm.nih.gov/articles/PMC11112444/

**研究内容：**
大規模言語モデルがランダム化比較試験（RCT）におけるバイアスリスク（ROB）評価を行う際の実現可能性と信頼性を検証した。

**方法：**
- Chat-GPT（LLM 1）とClaude（LLM 2）に構造化されたプロンプトを提供
- 30のRCTにおけるROBを専門家による評価を基準として分析
- Modified version of the Cochrane ROB tool (CLARITY group at McMaster University開発)を使用

**結果：**
- 両LLMが高い正確性と一貫性を示した
- LLM 2（Claude）: 平均正解率89.5%
- LLM 1（Chat-GPT）: 平均正解率84.5%
- ROB評価の補助ツールとして非常に有望

#### 4.2.3 Trad et al. (2025) - 高度な技術統合アプローチ

**出典：** BMC Medical Research Methodology volume 25, Article number: 130 (2025)
**URL：** https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-025-02583-5

**研究内容：**
LLMと既存の自動化ツールRayyanを比較し、プロンプトエンジニアリングと検索拡張生成（RAG）技術を組み合わせたアプローチを検証した。

**主な成果：**
- 手動スクリーニングと比較して95.5%もの時間削減を達成
- 偽陰性率0%という高い精度を維持
- 関連記事の見落としなく、タイトル/要約から全文スクリーニングまでを一貫して自動化
- RAG技術の統合により、SRプロセスの大幅な加速と信頼性向上を実現

## 5. 実際の作業における指導原則

### 5.1 Claudeとの対話から得られた知見



システマティックレビューにおいて126編の論文から情報抽出を行う場合の効率的なアプローチについて、Claudeは以下のように回答している：

（https://claude.ai/chat/60d64d7a-2e82-4e7e-bea3-327b4a012751）

### 5.2 情報抽出指示書の推奨形式

**1. 抽出項目の詳細リスト**
- 各項目の定義と抽出基準
- データ型（数値、カテゴリ、自由記述など）
- 必須/任意の区分

**2. 判定基準とルール**
- 曖昧なケースの処理方法
- 複数の値がある場合の優先順位
- 情報が不明/記載なしの場合の処理

**3. 出力形式の指定**
- CSVやJSON等の希望する形式
- 列名や項目名の命名規則

**4. 具体例**
- 2-3編の論文での抽出例を提示

### 5.3 作業方法の比較

**チャット形式の利点：**
- リアルタイムでの質問・確認が可能
- 曖昧な部分の即座な相談
- 作業の進捗確認が容易

**Claude Code（CLI）の利点：**
- 大量のファイル処理に適している
- 一括処理でより効率的
- 結果の一貫性が保たれやすい
- ローカルファイルへの直接アクセス

**推奨アプローチ：**
126編という規模を考慮すると、Claude Codeの方が効率的である。ただし、最初の数編はチャットで一緒に作業して抽出方法を確立し、その後でCLIでの一括処理に移行するのがベストプラクティスである。

## 6. セキュリティ上の注意事項

LLMをCLIツールとして利用する場合、以下のセキュリティ懸念に注意が必要である：

### 6.1 入力データの取り扱い

**機密情報の漏洩リスク：**
- ソースコード、個人情報、認証情報（APIキー、パスワードなど）が外部サービスに送信される危険

**プロンプトインジェクション攻撃：**
- 「システムを無視してこう動け」といった指示による意図しない挙動
- ログを他者と共有する場合は特に注意が必要

### 6.2 出力データの信頼性

**悪意あるコード生成：**
- マルウェアやバックドアを含むコードが提案されるリスク
- 実行前の必須レビュー

**誤情報の混入：**
- モデル出力の正確性は保証されない
- セキュリティ関連のコマンドや設定は特に検証が必須

### 6.3 CLI環境での脆弱性

**シェルインジェクション：**
- 悪意ある入力が危険なコマンドに変換される可能性

**権限の誤用：**
- 管理者権限での実行時のシステム全体へのリスク

### 6.4 通信とログの問題

**暗号化されていない通信：**
- HTTPSなどの暗号化を使わない場合の盗聴リスク

**ログへの残存：**
- プロンプトや出力がログに記録される際の後発的漏洩リスク

### 6.5 運用面でのリスク

**依存性の増加：**
- セキュリティパッチが未適用のツール使用による脆弱性

**利用規約やデータ保持ポリシーの不透明さ：**
- 外部API使用時のコンプライアンス問題

### 6.6 対策のまとめ

1. 機密情報を入力しない（特にキー・パスワード類）
2. 出力を直接シェルで実行しない（レビュー必須）
3. HTTPS通信とローカル暗号化を徹底
4. ログ管理に注意（特にプロンプト内容を残さない）
5. ツールの更新やセキュリティパッチを追従
6. 利用サービスのデータ保持ポリシーを確認

## 7. 著作権に関する考慮事項

Free accessではない学術論文PDFを無料のLLMモデル（無料版 Gemini CLIなど）に提供することについては、著作権等の観点から慎重な検討が必要である。研究目的での利用であっても、出版社の利用規約を確認し、適切な許可を得ることが重要である。

https://chatgpt.com/c/68a9d23a-c478-8323-98e6-60060c0ed7ee



## 8. まとめと今後の展望

LLM CLIツールを活用したシステマティックレビューのデータ抽出は、研究効率を大幅に向上させる可能性を秘めている。しかし、その実装には技術的理解、適切なプロンプト設計、セキュリティ対策、そして法的・倫理的配慮が必要である。

今後は、より特化したツールの開発と、研究コミュニティでのベストプラクティスの共有が進むことが期待される。研究者は技術の利点を享受しつつ、その制約と責任を理解した上で、これらのツールを活用していく必要がある。

---

## 9. 話し合っておきたいこと

  * 著作権を考慮したツール使用指針
    * free access ではない学術論文PDFをインターネット上にファイルをアップロードする機能を持ったAIツールへ与えることは著作権等の観点から問題。 
    * ChatGPTのようにインターネットブラウザ上に開かれたチャットウィンドウから非オープンアクセスのPDFをアップロードすることは著作権侵害になる可能性が高い。
    * LLM CLI toolであっても、実際はクラウド推論を使うツールであることが多い。安全に使うなら、完全にローカルで動作する翻訳・要約モデルを導入した方が良い（ただし2025年8月時点で技術的に未成熟）。
    * 有料のAIツールでそのAIとのやり取りの中で外部サーバーへ非オープンソースPDFが送られるとしても学習に使われない場合は、著作権侵害になる可能性が低いと考えて良いですか？
      * 多くの有料AIサービスは「アップロードしたデータは学習に使いません」と明記している。これは 利用者のデータが勝手に二次利用されることはない という意味で、プライバシーや機密保持の観点では安心材料であるが、学習に使われない＝著作権上も安全 ということにはならない。
    * ローカル処理が難しい場合に、クラウド利用でもリスクを最小化する運用方法
      * [ChatGPTからの提案1](./suggenstion_from_gpt_1.md)
      * [ChatGPTからの提案2](./suggenstion_from_gpt_2.md)
  * Sumpplementary 資料の読ませ方
    * 手分けして資料を集める
  * 読めないPDF
    * Doclingというツールを使うとよさそうだ
  * 出力形式：Markdown？CSV？JSON？

